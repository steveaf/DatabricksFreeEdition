{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60e269a5-8658-47b4-bdfe-b2edcd874be9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_date_from_string(input_string):\n",
    "    match = re.search(\n",
    "      # r'20\\d{2}[-_]?(0[1-9]|1[0-2])[-_]?(0[1-9]|[12]\\d|3[01])',\n",
    "        r'20\\d\\d[-_]?(?:0[1-9]|1[0-2])[-_]?(?:0[1-9]|[12]\\d|3[01])',\n",
    "        input_string\n",
    "    )\n",
    "    if not match:\n",
    "        return None\n",
    "    try:\n",
    "        date_str = match.group(0).replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "        return datetime.strptime(date_str, \"%Y%m%d\").date()\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19151bc7-b742-496f-8546-e9d9db856c60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, StructType, StructField,DateType\n",
    "\n",
    "\n",
    "incoming_dir = \"/Volumes/demos_standard/public_data/public_incoming/\"\n",
    "# Define the path to the source data\n",
    "file_path = f\"{incoming_dir}\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ident\", StringType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"elevation_ft\", StringType(), True),\n",
    "    StructField(\"continent\", StringType(), True),\n",
    "    StructField(\"iso_country\", StringType(), True),\n",
    "    StructField(\"iso_region\", StringType(), True),\n",
    "    StructField(\"municipality\", StringType(), True),\n",
    "    StructField(\"gps_code\", StringType(), True),\n",
    "    StructField(\"iata_code\", StringType(), True),\n",
    "    StructField(\"local_code\", StringType(), True),\n",
    "    StructField(\"coordinates\", StringType(), True),\n",
    "    StructField(\"source_file_name\", StringType(), True),\n",
    "    StructField(\"source_file_date\", DateType(), True)\n",
    "])\n",
    "\n",
    "@dp.table(\n",
    "  comment=\"Raw data of airports to kick the tires.\"\n",
    ")\n",
    "\n",
    "def airports_raw():\n",
    "  return ( \n",
    "    spark.read\n",
    "      .option(\"header\", \"true\")\n",
    "      .option(\"sep\", \",\")\n",
    "      .csv(file_path)\n",
    "      .withColumn(\n",
    "        \"source_file_name\",\n",
    "        regexp_extract(col(\"_metadata.file_path\"), r'([^/]+)$', 1))\n",
    "      .withColumn(\"source_file_date\", udf(extract_date_from_string, DateType())(col(\"source_file_name\")))\n",
    "  )\n",
    "\n",
    "\n",
    "# Define a materialized view that shows it works\n",
    "@dp.materialized_view(\n",
    "  comment=\"view of airports\"\n",
    ")\n",
    "@dp.expect(\"ID valid\", \"ID IS NOT NULL\")\n",
    "def airports_prepared():\n",
    "  return (\n",
    "    spark.read.table(\"airports_raw\")\n",
    "      .withColumnRenamed(\"ident\", \"ID\")\n",
    "      .withColumnRenamed(\"type\",\"AirportType\")\n",
    "      .withColumnRenamed(\"name\",\"AirportName\")\n",
    "      .withColumnRenamed(\"elevation_ft\",\"ElevationFt\")\n",
    "      .withColumnRenamed(\"continent\",\"Continent\")\n",
    "      .withColumnRenamed(\"iso_country\",\"Country\")\n",
    "      .withColumnRenamed(\"iso_region\",\"Region\")\n",
    "      .withColumnRenamed(\"municipality\",\"Municipality\")\n",
    "      # .withColumnRenamed(\"\",\"\")\n",
    "      # .withColumnRenamed(\"\",\"\")\n",
    "      .select(\"ID\", \"AirportType\", \"AirportName\", \"ElevationFt\", \"Continent\", \"Country\", \"Region\", \"Municipality\")\n",
    "  )\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93635fa7-4159-40d9-834d-5fc7b2f467cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "```\n",
    "# Define a materialized view that shows it works\n",
    "@dp.materialized_view(\n",
    "  comment=\"view of airports\"\n",
    ")\n",
    "@dp.expect(\"ident valid\", \"ident IS NOT NULL\")\n",
    "def airports_prepared():\n",
    "  return (\n",
    "    spark.read.table(\"airports_raw\")\n",
    "      .withColumnRenamed(\"ident\", \"ID\")\n",
    "      .select(\"ID\", \"type\", \"name\", \"elevation_ft\", \"continent\", \"iso_country\", \"iso_region\", \"municipality\")\n",
    "  )\n",
    "  ```"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "airports-load-bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
