{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fec5e8ed-ba20-4513-941b-8e19df280124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "%pip install py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f283d777-8b64-410c-ba7e-46d95ca5510f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import py7zr\n",
    "\n",
    "full_path_7z = \"/Volumes/demos_standard/public_data/public_raw/airport-codes.7z\"\n",
    "extract_dir = \"/Volumes/demos_standard/public_data/public_raw/tmp/airport_codes_extract\"\n",
    "\n",
    "with py7zr.SevenZipFile(full_path_7z, mode='r') as archive:\n",
    "    archive.extractall(path=extract_dir)\n",
    "\n",
    "import os\n",
    "csv_file = [f for f in os.listdir(extract_dir) if f.endswith('.csv')][0]\n",
    "csv_path = os.path.join(extract_dir, csv_file)\n",
    "\n",
    "df_all = spark.read.option(\"header\", \"true\").option(\"sep\", \",\").csv(csv_path)\n",
    "print(df_all.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "032a02c8-6401-45b6-ac02-974f78e374da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Total records: {df_all.count()}\")\n",
    "print(f\"Distinct ident count: {df_all.select('ident').distinct().count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97571fb5-db25-4003-afce-c6d79cec926e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_all.limit(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e50fa576-cc80-4b7d-be93-589777043d4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, when, col\n",
    "\n",
    "df_t_count = (\n",
    "    df_all.groupBy(\"type\")\n",
    "    .count()\n",
    "    .withColumn(\n",
    "        \"AirportSize\",\n",
    "        when(lower(col(\"type\")).contains(\"closed\"), \"Closed\")\n",
    "        .when(lower(col(\"type\")).contains(\"large\"), \"Large\")\n",
    "        .when(lower(col(\"type\")).contains(\"medium\"), \"Medium\")\n",
    "        .otherwise(\"Small\")\n",
    "    )\n",
    ")\n",
    "display(df_t_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b53e56b6-6da5-4c24-8834-dcb1abcc827b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_c_count = df_all.groupBy(\"continent\",\"iso_country\").count()\n",
    "display(df_c_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aee78458-e2ae-4a48-b886-c0e7705bc375",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765153826149}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_r_count = df_all.groupBy(\"iso_region\",\"continent\").count().orderBy(\"continent\",\"iso_region\")\n",
    "display(df_r_count)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "manual_7z_file",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
